{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msinan52/M-C-M-BL/blob/main/_3Bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "Z-xjFvjSM5Ok"
      },
      "id": "Z-xjFvjSM5Ok",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Veri yollarını belirtin\n",
        "data_dir = \"/content/drive/My Drive/1-a-brain/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]"
      ],
      "metadata": {
        "id": "zxoFqKh5M6Oi"
      },
      "id": "zxoFqKh5M6Oi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "data_dir = \"/content/drive/My Drive/1-a-brain/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]\n",
        "\n",
        "# Rastgele bir örnek seçme\n",
        "random_class = random.choice(class_names)\n",
        "random_image_path = os.path.join(data_dir, random_class, random.choice(os.listdir(os.path.join(data_dir, random_class))))\n",
        "random_image = cv2.imread(random_image_path)\n",
        "\n",
        "# Seçilen örneği görselleştirme\n",
        "plt.imshow(cv2.cvtColor(random_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Class: {random_class}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NuZqtYlBM6Q7"
      },
      "id": "NuZqtYlBM6Q7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/1-a-brain/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]\n",
        "# Toplam etiket ve resim sayıları\n",
        "total_labels = 0\n",
        "total_images = 0\n",
        "\n",
        "# Her sınıf için etiket ve resim sayılarını hesapla\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    class_labels = len(os.listdir(class_dir))\n",
        "    class_images = len([f for f in os.listdir(class_dir) if f.endswith('.png')])  # .jpg uzantılı dosyaları say\n",
        "\n",
        "    total_labels += class_labels\n",
        "    total_images += class_images\n",
        "\n",
        "    print(f\"Sınıf: {class_name}, Etiket Sayısı: {class_labels}, Resim Sayısı: {class_images}\")\n",
        "\n",
        "# Toplam etiket ve resim sayılarını yazdır\n",
        "print(f\"\\nToplam Etiket Sayısı: {total_labels}\")\n",
        "print(f\"Toplam Resim Sayısı: {total_images}\")\n"
      ],
      "metadata": {
        "id": "RtNYfWFAM6TM"
      },
      "id": "RtNYfWFAM6TM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Check if the image is loaded successfully\n",
        "        if img is not None:\n",
        "            # Resize the image to 64x64\n",
        "            img_resized = cv2.resize(img, (64, 64))\n",
        "\n",
        "            data.append(img_resized)\n",
        "            labels.append(class_name)\n",
        "        else:\n",
        "            print(f\"Error loading image: {img_path}\")\n",
        "\n",
        "# Continue with the rest of your code\n"
      ],
      "metadata": {
        "id": "b0XYobd2M-f2"
      },
      "id": "b0XYobd2M-f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy dizilerine dönüştürme\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "cMBwzDWZM-ia"
      },
      "id": "cMBwzDWZM-ia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Now, you can use to_categorical\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=2)\n",
        "test_labels_onehot = to_categorical(test_labels, num_classes=2)"
      ],
      "metadata": {
        "id": "PE5q96hoNBiD"
      },
      "id": "PE5q96hoNBiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming each input at a time step is a 64x64 image with 3 channels\n",
        "train_data_reshaped = train_data.reshape(train_data.shape[0], 64, 64 * 3)"
      ],
      "metadata": {
        "id": "oKOXJzAXNBkK"
      },
      "id": "oKOXJzAXNBkK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, Dense\n",
        "\n",
        "# Modeli oluşturma\n",
        "model = Sequential()\n",
        "\n",
        "# Bidirectional LSTM katmanları\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(64, 64*3)))  # 64*3: 64x64 boyutlu ve 3 kanallı görüntüden düzleştirilmiş hali\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "\n",
        "# Flatten ve Dense katmanları\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "# Modeli derleme\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model özeti\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "biIjMfIoNFe4"
      },
      "id": "biIjMfIoNFe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBpVIJkKNFhG"
      },
      "id": "xBpVIJkKNFhG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_c03DSDpllv"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "# Modeli derleme\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ReduceLROnPlateau ve EarlyStopping callback'leri\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, mode='auto', factor=0.3, min_lr=0.000001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Modeli eğitme\n",
        "history2 = model.fit(\n",
        "    train_data_reshaped, train_labels_onehot,\n",
        "    epochs=100,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")"
      ],
      "id": "D_c03DSDpllv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgmsg3urkgL4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Get the training and validation metrics\n",
        "train_accuracy = history2.history['accuracy']\n",
        "train_loss = history2.history['loss']\n",
        "\n",
        "\n",
        "val_accuracy = history2.history['val_accuracy']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "\n",
        "# Plot the metrics\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n"
      ],
      "id": "bgmsg3urkgL4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwJLALMxz393"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Get the training and validation metrics\n",
        "train_accuracy = history2.history['accuracy']\n",
        "train_loss = history2.history['loss']\n",
        "\n",
        "\n",
        "val_accuracy = history2.history['val_accuracy']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "\n",
        "# Plot the metrics\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n"
      ],
      "id": "BwJLALMxz393"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZUnvsC_IcEg"
      },
      "source": [
        "#keras tunner"
      ],
      "id": "UZUnvsC_IcEg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NRWQrLS6ZKu",
        "outputId": "344175ec-8414-4fc9-bac9-dc1ab1f07efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ],
      "id": "-NRWQrLS6ZKu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFTL2dIWIjBo"
      },
      "outputs": [],
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.applications import DenseNet121\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "# Model function definition\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    # TimeDistributed LSTM layers\n",
        "    model.add(TimeDistributed(Bidirectional(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
        "                                                return_sequences=True))))\n",
        " # TimeDistributed LSTM layers\n",
        "    model.add(TimeDistributed(Bidirectional(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
        "                                                return_sequences=True))))\n",
        "\n",
        "    # Flatten and Dense layers\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(Bidirectional(LSTM(units=hp.Int('dense_units', min_value=32, max_value=512, step=32),\n",
        "                                 return_sequences=True)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Tuner creation\n",
        "tuner = kt.BayesianOptimization(build_model,\n",
        "                                objective='val_accuracy',\n",
        "                                max_trials=10,  # You can adjust the number of trials\n",
        "                                directory='my_dir',\n",
        "                                project_name='helloworld')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, mode='auto', factor=0.3, min_lr=0.000001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "# Convert the image data to float32\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "# Normalize the image data to the range [0, 1]\n",
        "train_data /= 255.0\n",
        "test_data /= 255.0\n",
        "\n",
        "# Tuner search\n",
        "tuner.search(train_data, train_labels_onehot, epochs=100, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model\n",
        "history = best_model.fit(train_data, train_labels_onehot, epochs=100, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Modeli değerlendirme\n",
        "accuracy = best_model.evaluate(test_data, test_labels_onehot)[1]\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "# Modeli değerlendir\n",
        "evaluation = best_model.evaluate(test_data, test_labels_onehot)\n",
        "test_accuracy = evaluation[1]\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n"
      ],
      "id": "pFTL2dIWIjBo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvmXYSnt4esw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "true_labels = test_labels_onehot\n",
        "\n",
        "predicted_probabilities = best_model.predict(test_data)\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Sınıflandırma raporunu al\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = best_model.predict(test_data)\n",
        "\n",
        "# Tahminleri sınıf etiketlerine dönüştür\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Doğru etiketleri al\n",
        "true_labels = test_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Karışıklık matrisini oluştur\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Karışıklık matrisini görselleştir\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "hm = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", xticklabels=class_names, yticklabels=class_names)\n",
        "hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom=False)\n",
        "plt.xlabel('AI Prediction')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Get the training and validation metrics\n",
        "train_accuracy = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "\n",
        "\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "# Plot the metrics\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = best_model.predict(test_data)\n",
        "\n",
        "# Gerçek etiketleri al\n",
        "true_labels_positive = test_labels_onehot[:, 1]   # İkinci sütun (1) pozitif sınıfı temsil eder\n",
        "\n",
        "# ROC eğrisini ve AUC değerini hesapla\n",
        "fpr, tpr, thresholds = roc_curve(true_labels_positive, predicted_probabilities[:, 1])  # predicted_probabilities'ın ikinci sütunu pozitif sınıfı temsil eder\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# ROC eğrisini çizdir\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "id": "qvmXYSnt4esw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcyzuPZ7usaa"
      },
      "outputs": [],
      "source": [],
      "id": "UcyzuPZ7usaa"
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}