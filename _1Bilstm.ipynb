{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msinan52/M-C-M-BL/blob/main/_1Bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Veri yollarını belirtin\n",
        "data_dir = \"/content/drive/My Drive/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "data_dir = \"/content/drive/My Drive/1-a-brain/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]\n",
        "\n",
        "# Rastgele bir örnek seçme\n",
        "random_class = random.choice(class_names)\n",
        "random_image_path = os.path.join(data_dir, random_class, random.choice(os.listdir(os.path.join(data_dir, random_class))))\n",
        "random_image = cv2.imread(random_image_path)\n",
        "\n",
        "# Seçilen örneği görselleştirme\n",
        "plt.imshow(cv2.cvtColor(random_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Class: {random_class}')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/1-a-brain/80-20\"  # Veri klasörünün kök dizini\n",
        "class_names = [\"no\",\"yes\"]\n",
        "# Toplam etiket ve resim sayıları\n",
        "total_labels = 0\n",
        "total_images = 0\n",
        "\n",
        "# Her sınıf için etiket ve resim sayılarını hesapla\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    class_labels = len(os.listdir(class_dir))\n",
        "    class_images = len([f for f in os.listdir(class_dir) if f.endswith('.png')])  # .jpg uzantılı dosyaları say\n",
        "\n",
        "    total_labels += class_labels\n",
        "    total_images += class_images\n",
        "\n",
        "    print(f\"Sınıf: {class_name}, Etiket Sayısı: {class_labels}, Resim Sayısı: {class_images}\")\n",
        "\n",
        "# Toplam etiket ve resim sayılarını yazdır\n",
        "print(f\"\\nToplam Etiket Sayısı: {total_labels}\")\n",
        "print(f\"Toplam Resim Sayısı: {total_images}\")\n",
        "\n",
        "# Veri ve etiketleri toplama\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "        img = cv2.imread(img_path)  # Resmi yükleme, gerekirse boyut değişikliği yapılabilir\n",
        "        data.append(cv2.resize(img, (64, 64)))  # Resmi 64x64 boyutuna yeniden boyutlandırma\n",
        "        labels.append(class_name)\n",
        "\n",
        "# NumPy dizilerine dönüştürme\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırma\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Now, you can use to_categorical\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=2)\n",
        "test_labels_onehot = to_categorical(test_labels, num_classes=2)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, Conv2D, MaxPooling2D, Flatten, Dense, TimeDistributed\n",
        "\n",
        "# Modeli oluşturma\n",
        "model = Sequential()\n",
        "\n",
        "# Conv2D katmanları\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# TimeDistributed katmanı\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# LSTM katmanları\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "# Flatten ve Dense katmanları\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the summary\n",
        "model.summary()\n",
        "\n",
        "from keras import metrics\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, mode='auto', factor=0.3, min_lr=0.000001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(train_data, train_labels_onehot, epochs=100, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Get the training and validation metrics\n",
        "train_accuracy = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "\n",
        "\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "# Plot the metrics\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, color='blue', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='black', label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig(\"acc_CNN_uclu.png\")\n",
        "plt.show()\n",
        "\n",
        "# Modeli değerlendirme\n",
        "accuracy = model.evaluate(test_data, test_labels_onehot)[1]\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "# Modeli değerlendir\n",
        "evaluation = model.evaluate(test_data, test_labels_onehot)\n",
        "test_accuracy = evaluation[1]\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = model.predict(test_data)\n",
        "\n",
        "# Tahminleri sınıf etiketlerine dönüştür\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Doğru etiketleri al\n",
        "true_labels = test_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Karışıklık matrisini oluştur\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Karışıklık matrisini görselleştir\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "hm = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", xticklabels=class_names, yticklabels=class_names)\n",
        "hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom=False)\n",
        "plt.xlabel('AI Prediction')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sınıflandırma raporunu al\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = model.predict(test_data)\n",
        "\n",
        "# Gerçek etiketleri al\n",
        "true_labels_positive = test_labels_onehot[:, 1]   # İkinci sütun (1) pozitif sınıfı temsil eder\n",
        "\n",
        "# ROC eğrisini ve AUC değerini hesapla\n",
        "fpr, tpr, thresholds = roc_curve(true_labels_positive, predicted_probabilities[:, 1])  # predicted_probabilities'ın ikinci sütunu pozitif sınıfı temsil eder\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# ROC eğrisini çizdir\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03ByJnMEG5Gm"
      },
      "id": "03ByJnMEG5Gm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usNhB6PPG5Mf"
      },
      "id": "usNhB6PPG5Mf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#keras tunner"
      ],
      "metadata": {
        "id": "UZUnvsC_IcEg"
      },
      "id": "UZUnvsC_IcEg"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "id": "-NRWQrLS6ZKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727d00a3-b1da-4c61-d9ef-ff3d254cf386"
      },
      "id": "-NRWQrLS6ZKu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.applications import DenseNet121\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "# Model function definition\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    # TimeDistributed LSTM layers\n",
        "    model.add(TimeDistributed(Bidirectional(LSTM(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
        "                                                return_sequences=True))))\n",
        "\n",
        "\n",
        "    # Flatten and Dense layers\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(Bidirectional(LSTM(units=hp.Int('dense_units', min_value=32, max_value=256, step=32),\n",
        "                                 return_sequences=True)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Tuner creation\n",
        "tuner = kt.BayesianOptimization(build_model,\n",
        "                                objective='val_accuracy',\n",
        "                                max_trials=10,  # You can adjust the number of trials\n",
        "                                directory='my_dir',\n",
        "                                project_name='helloworld')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, mode='auto', factor=0.3, min_lr=0.000001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "# Convert the image data to float32\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "# Normalize the image data to the range [0, 1]\n",
        "train_data /= 255.0\n",
        "test_data /= 255.0\n",
        "\n",
        "# Tuner search\n",
        "tuner.search(train_data, train_labels_onehot, epochs=100, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model\n",
        "history = best_model.fit(train_data, train_labels_onehot, epochs=100, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Modeli değerlendirme\n",
        "accuracy = best_model.evaluate(test_data, test_labels_onehot)[1]\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "# Modeli değerlendir\n",
        "evaluation = best_model.evaluate(test_data, test_labels_onehot)\n",
        "test_accuracy = evaluation[1]\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sınıflandırma raporunu al\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = best_model.predict(test_data)\n",
        "\n",
        "# Tahminleri sınıf etiketlerine dönüştür\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Doğru etiketleri al\n",
        "true_labels = test_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Karışıklık matrisini oluştur\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Karışıklık matrisini görselleştir\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "hm = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", xticklabels=class_names, yticklabels=class_names)\n",
        "hm.tick_params(labeltop=True, labelbottom=False, top=True, bottom=False)\n",
        "plt.xlabel('AI Prediction')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Get the training and validation metrics\n",
        "train_accuracy = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "\n",
        "\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "# Plot the metrics\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(epochs)  # Set the x-axis ticks explicitly\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Tahminleri yap\n",
        "predicted_probabilities = best_model.predict(test_data)\n",
        "\n",
        "# Gerçek etiketleri al\n",
        "true_labels_positive = test_labels_onehot[:, 1]   # İkinci sütun (1) pozitif sınıfı temsil eder\n",
        "\n",
        "# ROC eğrisini ve AUC değerini hesapla\n",
        "fpr, tpr, thresholds = roc_curve(true_labels_positive, predicted_probabilities[:, 1])  # predicted_probabilities'ın ikinci sütunu pozitif sınıfı temsil eder\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# ROC eğrisini çizdir\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F-LSnXDZsnJG"
      },
      "id": "F-LSnXDZsnJG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-4xbYvm-vd20"
      },
      "id": "-4xbYvm-vd20",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}